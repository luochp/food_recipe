Start
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1        [100, 64, 224, 224]           1,792
              ReLU-2        [100, 64, 224, 224]               0
            Conv2d-3        [100, 64, 224, 224]          36,928
              ReLU-4        [100, 64, 224, 224]               0
         MaxPool2d-5        [100, 64, 112, 112]               0
            Conv2d-6       [100, 128, 112, 112]          73,856
              ReLU-7       [100, 128, 112, 112]               0
            Conv2d-8       [100, 128, 112, 112]         147,584
              ReLU-9       [100, 128, 112, 112]               0
        MaxPool2d-10         [100, 128, 56, 56]               0
           Conv2d-11         [100, 256, 56, 56]         295,168
             ReLU-12         [100, 256, 56, 56]               0
           Conv2d-13         [100, 256, 56, 56]         590,080
             ReLU-14         [100, 256, 56, 56]               0
           Conv2d-15         [100, 256, 56, 56]         590,080
             ReLU-16         [100, 256, 56, 56]               0
        MaxPool2d-17         [100, 256, 28, 28]               0
           Conv2d-18         [100, 512, 28, 28]       1,180,160
             ReLU-19         [100, 512, 28, 28]               0
           Conv2d-20         [100, 512, 28, 28]       2,359,808
             ReLU-21         [100, 512, 28, 28]               0
           Conv2d-22         [100, 512, 28, 28]       2,359,808
             ReLU-23         [100, 512, 28, 28]               0
        MaxPool2d-24         [100, 512, 14, 14]               0
           Conv2d-25         [100, 512, 14, 14]       2,359,808
             ReLU-26         [100, 512, 14, 14]               0
           Conv2d-27         [100, 512, 14, 14]       2,359,808
             ReLU-28         [100, 512, 14, 14]               0
           Conv2d-29         [100, 512, 14, 14]       2,359,808
             ReLU-30         [100, 512, 14, 14]               0
        MaxPool2d-31           [100, 512, 7, 7]               0
AdaptiveAvgPool2d-32           [100, 512, 7, 7]               0
           Linear-33                [100, 4096]     102,764,544
             ReLU-34                [100, 4096]               0
          Dropout-35                [100, 4096]               0
           Linear-36                [100, 4096]      16,781,312
             ReLU-37                [100, 4096]               0
          Dropout-38                [100, 4096]               0
           Linear-39                 [100, 256]       1,048,832
             ReLU-40                 [100, 256]               0
          Dropout-41                 [100, 256]               0
           Linear-42                 [100, 100]          25,700
       LogSoftmax-43                 [100, 100]               0
================================================================
Total params: 135,335,076
Trainable params: 1,074,532
Non-trainable params: 134,260,544
----------------------------------------------------------------
Input size (MB): 57.42
Forward/backward pass size (MB): 21878.08
Params size (MB): 516.26
Estimated Total Size (MB): 22451.77
----------------------------------------------------------------
Starting Training from Scratch.


Epoch: 0 	Training Loss: 3.8476 	Validation Loss: 3.6564
		Training Accuracy: 37.73 	 Validation Accuracy: 43.62

Epoch: 1 	Training Loss: 3.6635 	Validation Loss: 3.6035
		Training Accuracy: 41.95 	 Validation Accuracy: 44.74

Epoch: 2 	Training Loss: 3.6030 	Validation Loss: 3.5729
		Training Accuracy: 43.65 	 Validation Accuracy: 44.57

Epoch: 3 	Training Loss: 3.5703 	Validation Loss: 3.5698
		Training Accuracy: 44.64 	 Validation Accuracy: 45.39

Epoch: 4 	Training Loss: 3.5434 	Validation Loss: 3.5390
		Training Accuracy: 44.81 	 Validation Accuracy: 46.27

Epoch: 5 	Training Loss: 3.5181 	Validation Loss: 3.5427
		Training Accuracy: 45.48 	 Validation Accuracy: 45.73

Epoch: 6 	Training Loss: 3.4971 	Validation Loss: 3.5480
		Training Accuracy: 45.88 	 Validation Accuracy: 46.12

Epoch: 7 	Training Loss: 3.4827 	Validation Loss: 3.5475
		Training Accuracy: 46.02 	 Validation Accuracy: 45.64

Epoch: 8 	Training Loss: 3.4650 	Validation Loss: 3.5507
		Training Accuracy: 46.45 	 Validation Accuracy: 45.05

Epoch: 9 	Training Loss: 3.4529 	Validation Loss: 3.5390
		Training Accuracy: 46.77 	 Validation Accuracy: 45.68

Epoch: 10 	Training Loss: 3.4424 	Validation Loss: 3.5339
		Training Accuracy: 46.94 	 Validation Accuracy: 45.83

Epoch: 11 	Training Loss: 3.4321 	Validation Loss: 3.5440
		Training Accuracy: 47.03 	 Validation Accuracy: 45.00

Epoch: 12 	Training Loss: 3.4172 	Validation Loss: 3.5454
		Training Accuracy: 47.22 	 Validation Accuracy: 46.22

Epoch: 13 	Training Loss: 3.4124 	Validation Loss: 3.5434
		Training Accuracy: 47.33 	 Validation Accuracy: 45.64

Epoch: 14 	Training Loss: 3.4017 	Validation Loss: 3.5556
		Training Accuracy: 47.49 	 Validation Accuracy: 45.37

Epoch: 15 	Training Loss: 3.3915 	Validation Loss: 3.5375
		Training Accuracy: 47.93 	 Validation Accuracy: 46.31

Epoch: 16 	Training Loss: 3.3846 	Validation Loss: 3.5498
		Training Accuracy: 48.21 	 Validation Accuracy: 45.73

Epoch: 17 	Training Loss: 3.3721 	Validation Loss: 3.5522
		Training Accuracy: 48.41 	 Validation Accuracy: 45.88

Epoch: 18 	Training Loss: 3.3809 	Validation Loss: 3.5599
		Training Accuracy: 48.17 	 Validation Accuracy: 45.78

Epoch: 19 	Training Loss: 3.3607 	Validation Loss: 3.5611
		Training Accuracy: 48.45 	 Validation Accuracy: 45.76

Epoch: 20 	Training Loss: 3.3591 	Validation Loss: 3.5653
		Training Accuracy: 48.50 	 Validation Accuracy: 45.97

Epoch: 21 	Training Loss: 3.3512 	Validation Loss: 3.5497
		Training Accuracy: 48.61 	 Validation Accuracy: 45.81

Epoch: 22 	Training Loss: 3.3516 	Validation Loss: 3.5523
		Training Accuracy: 48.82 	 Validation Accuracy: 45.17

Early Stopping! Total epochs: 22. Best epoch: 10 with loss: 3.53 and acc: 45.17
7345.13 total seconds elapsed. 319.35 seconds per epoch.
Done
